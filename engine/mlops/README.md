# MLOps Layer

Capa MLOps integrada en Tauro para **Model Registry** y **Experiment Tracking**, con soporte dual para almacenamiento local (Parquet) y Databricks Unity Catalog.

## üéØ Filosof√≠a: Invisible hasta que se necesite

MLOps en Tauro est√° dise√±ado para ser:
- **Zero-config para ETL**: No interfiere con pipelines de solo datos
- **Auto-activado para ML**: Detecta autom√°ticamente nodos ML
- **Progresivamente complejo**: Configuraci√≥n simple por defecto, control fino cuando se necesita

---

## Caracter√≠sticas

### Model Registry
- ‚úÖ Versionado autom√°tico de modelos
- ‚úÖ Metadatos estructurados (framework, hiperpar√°metros, m√©tricas)
- ‚úÖ Almacenamiento de artefactos (sklearn, XGBoost, PyTorch, etc.)
- ‚úÖ Gesti√≥n del ciclo de vida (Staging ‚Üí Production ‚Üí Archived)
- ‚úÖ B√∫squeda por nombre, versi√≥n y etapa
- ‚úÖ Tags y anotaciones

### Experiment Tracking
- ‚úÖ Creaci√≥n de experimentos y runs
- ‚úÖ Logging de m√©tricas (con timestamps y steps)
- ‚úÖ Logging de hiperpar√°metros
- ‚úÖ Almacenamiento de artefactos por run
- ‚úÖ Comparaci√≥n de runs (DataFrame)
- ‚úÖ B√∫squeda de runs por m√©tricas
- ‚úÖ Soporte para runs anidados (parent-child)

### Backends
- ‚úÖ **Local**: Almacenamiento en Parquet (sin dependencias externas)
- ‚úÖ **Databricks**: Unity Catalog (con databricks-sql-connector)

### Integraci√≥n con Exec
- ‚úÖ **Auto-detection**: Detecta nodos ML autom√°ticamente
- ‚úÖ **Lazy initialization**: Solo se carga si hay nodos ML
- ‚úÖ **Factory pattern**: Auto-configura backend (local/Databricks)
- ‚úÖ **ml_info.yaml**: Configuraci√≥n ML centralizada (opcional)

---

## Quick Start

### Instalaci√≥n

```bash
pip install pandas loguru pyarrow

# Para Databricks (opcional)
pip install databricks-sql-connector
```

### Uso B√°sico

#### 1. Inicializar MLOps Context

**Opci√≥n A: Desde Tauro Context (RECOMENDADO - Auto mode detection)**

```python
from tauro.core.config import Context
from tauro.core.mlops.config import MLOpsContext

# Crear context de Tauro
context = Context(
    global_settings="config/global_settings.yaml",
    pipelines_config="config/pipelines.yaml",
    nodes_config="config/nodes.yaml",
    input_config="config/input.yaml",
    output_config="config/output.yaml",
)

# MLOps auto-detecta modo (local/databricks) desde context
mlops = MLOpsContext.from_context(context)
# ‚úÖ Auto-configura backend basado en execution_mode
# ‚úÖ Usa configuraci√≥n de global_settings
# ‚úÖ Soporta P1 features (buffering, locking, etc.)
```

**Opci√≥n B: Manual (Para uso standalone)**

```python
from tauro.core.mlops.config import MLOpsContext

# Local backend expl√≠cito
ctx = MLOpsContext(
    backend_type="local",
    storage_path="./mlops_data"
)

# Databricks backend expl√≠cito
ctx = MLOpsContext(
    backend_type="databricks",
    databricks_catalog="main",
    databricks_schema="ml_tracking",
)
```

**Opci√≥n C: Desde variables de entorno (DEPRECATED)**

```python
# ‚ö†Ô∏è DEPRECATED: Use from_context() for auto mode detection
ctx = MLOpsContext.from_env()
```

#### 2. Model Registry

```python
registry = ctx.model_registry

# Registrar modelo
model_v1 = registry.register_model(
    name="credit_risk_model",
    artifact_path="/path/to/model.pkl",
    artifact_type="sklearn",
    framework="scikit-learn",
    hyperparameters={"n_estimators": 100, "max_depth": 10},
    metrics={"accuracy": 0.92, "auc": 0.95},
    tags={"team": "ds", "project": "credit"}
)

# Listar modelos
models = registry.list_models()

# Obtener versi√≥n espec√≠fica
model = registry.get_model_version("credit_risk_model", version=1)

# Promover a producci√≥n
registry.promote_model("credit_risk_model", 1, ModelStage.PRODUCTION)

# Descargar artefacto
registry.download_artifact("credit_risk_model", None, "/local/path")
```

#### 3. Experiment Tracking

```python
tracker = ctx.experiment_tracker

# Crear experimento
exp = tracker.create_experiment(
    name="model_tuning_v1",
    description="Hyperparameter tuning",
    tags={"team": "ds"}
)

# Iniciar run
run = tracker.start_run(
    exp.experiment_id,
    name="trial_1",
    parameters={"lr": 0.01, "batch_size": 32}
)

# Loguear m√©tricas
for epoch in range(10):
    tracker.log_metric(run.run_id, "loss", 0.5 - epoch * 0.05, step=epoch)
    tracker.log_metric(run.run_id, "accuracy", 0.7 + epoch * 0.03, step=epoch)

# Loguear artefactos
tracker.log_artifact(run.run_id, "/path/to/model.pkl")

# Terminar run
tracker.end_run(run.run_id, RunStatus.COMPLETED)

# Buscar runs
matching_runs = tracker.search_runs(
    exp.experiment_id,
    metric_filter={"accuracy": (">", 0.85)}
)

# Comparar runs
comparison_df = tracker.compare_runs([run1.run_id, run2.run_id])
```

---

## üì¶ Configuraci√≥n con ml_info.yaml

Para proyectos ML complejos, puedes centralizar la configuraci√≥n en `ml_info.yaml`:

```yaml
# config/ml_info.yaml
mlops:
  enabled: true
  backend: "databricks"
  experiment:
    name: "customer-churn-prediction"
    description: "Modelo de abandono de clientes"
  model_registry:
    catalog: "main"
    schema: "ml_models"
  tracking:
    catalog: "main"
    schema: "ml_experiments"
  auto_log: true
```

### Precedencia de Configuraci√≥n

La configuraci√≥n MLOps sigue esta jerarqu√≠a (de mayor a menor prioridad):

1. **Node config** (`nodes.yaml` - espec√≠fico del nodo)
2. **Pipeline config** (`pipelines.yaml` - nivel pipeline)
3. **ml_info.yaml** (configuraci√≥n ML centralizada)
4. **Global settings** (`global_settings.yaml`)
5. **Auto-defaults** (valores por defecto inteligentes)

**Ejemplo de uso combinado:**

```yaml
# config/nodes.yaml
nodes:
  train_model:
    type: "ml_training"
    config:
      mlops:
        experiment_name: "xgboost-tuning"  # ‚Üê Override solo esto
        # Resto hereda de ml_info.yaml o global_settings
```

**Ventajas:**
- ‚úÖ Un solo lugar para configuraci√≥n ML com√∫n
- ‚úÖ Override selectivo a nivel pipeline/nodo
- ‚úÖ Separaci√≥n clara entre config ML y config datos
- ‚úÖ Reusabilidad entre pipelines ML

**Ver m√°s:**
- [SIMPLIFICATION_PROPOSAL.md](../../../SIMPLIFICATION_PROPOSAL.md) - Dise√±o completo
- [MLOPS_SIMPLE_GUIDE.md](../../../MLOPS_SIMPLE_GUIDE.md) - Gu√≠a r√°pida con ejemplos

---

## Arquitectura

```
tauro/core/mlops/
‚îú‚îÄ‚îÄ __init__.py              # Public API
‚îú‚îÄ‚îÄ storage.py               # Storage backends (Local, Databricks)
‚îú‚îÄ‚îÄ model_registry.py        # Model Registry implementation
‚îú‚îÄ‚îÄ experiment_tracking.py   # Experiment Tracking implementation
‚îú‚îÄ‚îÄ config.py                # MLOpsContext y configuraci√≥n
‚îú‚îÄ‚îÄ example.py               # Ejemplos de uso
‚îî‚îÄ‚îÄ README.md                # Esta documentaci√≥n

tauro/core/exec/
‚îú‚îÄ‚îÄ mlops_auto_config.py     # Auto-detection y config merge
‚îî‚îÄ‚îÄ executor.py              # Lazy initialization en BaseExecutor
```

### Componentes Clave

1. **StorageBackend** (`storage.py`):
   - Abstracci√≥n para local (Parquet) y Databricks (Unity Catalog)
   - API unificada: write_dataframe, read_dataframe, write_json, etc.

2. **ModelRegistry** (`model_registry.py`):
   - Versionado de modelos
   - Lifecycle management (Staging/Production/Archived)
   - Metadatos y artefactos

3. **ExperimentTracker** (`experiment_tracking.py`):
   - Experiments y runs
   - M√©tricas, hiperpar√°metros, artefactos
   - Comparaci√≥n de runs

4. **MLOpsContext** (`config.py`):
   - Factory para backend selection
   - Configuraci√≥n centralizada
   - from_context() para auto mode detection

5. **MLOpsAutoConfigurator** (`tauro/core/exec/mlops_auto_config.py`):
   - Detecta autom√°ticamente nodos ML (patterns)
   - Genera configuraci√≥n por defecto inteligente
   - Merge jer√°rquico: node ‚Üí pipeline ‚Üí ml_info ‚Üí global ‚Üí auto

6. **BaseExecutor Integration** (`tauro/core/exec/executor.py`):
   - Lazy initialization: solo carga si hay nodos ML
   - Property `mlops_context`: acceso on-demand
   - Auto-skip para pipelines ETL puros

### Storage Backend Abstraction

Todos los componentes usan una abstracci√≥n `StorageBackend`:

```python
class StorageBackend(ABC):
    def write_dataframe(df, path) -> StorageMetadata
    def read_dataframe(path) -> pd.DataFrame
    def write_json(data, path) -> StorageMetadata
    def read_json(path) -> Dict
    def write_artifact(src, dest) -> StorageMetadata
    def read_artifact(src, dest_local) -> None
    def exists(path) -> bool
    def list_paths(prefix) -> List[str]
    def delete(path) -> None
```

**LocalStorageBackend**: Usa Parquet para DataFrames, JSON para metadatos, archivos nativos para artefactos.

**DatabricksStorageBackend**: Integraci√≥n con Unity Catalog (requiere API adicional para escritura).

---

## Estructura de Datos

### Model Registry

```
model_registry/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ index.parquet                    # √çndice de modelos
‚îÇ   ‚îî‚îÄ‚îÄ .registry_marker.json
‚îú‚îÄ‚îÄ metadata/
‚îÇ   ‚îî‚îÄ‚îÄ {model_id}/
‚îÇ       ‚îú‚îÄ‚îÄ v1.json                      # Metadata v1
‚îÇ       ‚îú‚îÄ‚îÄ v2.json                      # Metadata v2
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ artifacts/
    ‚îî‚îÄ‚îÄ {model_id}/
        ‚îú‚îÄ‚îÄ v1/                          # Artefactos v1
        ‚îú‚îÄ‚îÄ v2/                          # Artefactos v2
        ‚îî‚îÄ‚îÄ ...
```

### Experiment Tracking

```
experiment_tracking/
‚îú‚îÄ‚îÄ experiments/
‚îÇ   ‚îú‚îÄ‚îÄ index.parquet                    # √çndice de experimentos
‚îÇ   ‚îú‚îÄ‚îÄ {exp_id}.json                    # Metadata experimento
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ runs/
‚îÇ   ‚îî‚îÄ‚îÄ {exp_id}/
‚îÇ       ‚îú‚îÄ‚îÄ index.parquet                # √çndice de runs
‚îÇ       ‚îú‚îÄ‚îÄ {run_id}.json                # Metadata run
‚îÇ       ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ artifacts/
    ‚îî‚îÄ‚îÄ {run_id}/                        # Artefactos del run
        ‚îú‚îÄ‚îÄ model.pkl
        ‚îú‚îÄ‚îÄ predictions.parquet
        ‚îî‚îÄ‚îÄ ...
```

---

## Configuraci√≥n

### Variables de Entorno

```bash
# Local backend
TAURO_MLOPS_BACKEND=local
TAURO_MLOPS_PATH=/path/to/mlops/data

# Databricks backend
TAURO_MLOPS_BACKEND=databricks
TAURO_MLOPS_CATALOG=my_catalog
TAURO_MLOPS_SCHEMA=mlops
DATABRICKS_HOST=https://workspace.cloud.databricks.com
DATABRICKS_TOKEN=dapi1234567890abcdef
```

### Inicializaci√≥n Program√°tica

```python
# Local
ctx = MLOpsContext(
    backend_type="local",
    storage_path="./mlops_data"
)

# Databricks
ctx = MLOpsContext(
    backend_type="databricks",
    databricks_catalog="my_catalog",
    databricks_schema="mlops",
    databricks_workspace_url="https://...",
    databricks_token="dapi..."
)
```

---

## API Reference

### ModelRegistry

#### `register_model()`
```python
def register_model(
    name: str,
    artifact_path: str,
    artifact_type: str,
    framework: str,
    description: str = "",
    hyperparameters: Dict = None,
    metrics: Dict = None,
    tags: Dict = None,
    input_schema: Dict = None,
    output_schema: Dict = None,
    dependencies: List = None,
    experiment_run_id: str = None,
) -> ModelVersion
```

Registra un nuevo modelo o versi√≥n. Incrementa autom√°ticamente el n√∫mero de versi√≥n si el modelo ya existe.

#### `get_model_version()`
```python
def get_model_version(
    name: str,
    version: int = None,
) -> ModelVersion
```

Obtiene una versi√≥n espec√≠fica (o la √∫ltima si `version=None`).

#### `list_models()` ‚Üí `List[Dict]`

Lista todos los modelos con su versi√≥n m√°s reciente.

#### `list_model_versions()` ‚Üí `List[Dict]`

Lista todas las versiones de un modelo.

#### `promote_model()`
```python
def promote_model(
    name: str,
    version: int,
    stage: ModelStage
) -> ModelVersion
```

Promueve modelo a Staging, Production o Archived.

#### `download_artifact()`
```python
def download_artifact(
    name: str,
    version: int,
    local_destination: str
) -> None
```

Descarga artefacto del modelo a ruta local.

---

### ExperimentTracker

#### `create_experiment()`
```python
def create_experiment(
    name: str,
    description: str = "",
    tags: Dict = None,
) -> Experiment
```

Crea nuevo experimento.

#### `start_run()`
```python
def start_run(
    experiment_id: str,
    name: str = "",
    parameters: Dict = None,
    tags: Dict = None,
    parent_run_id: str = None,
) -> Run
```

Inicia nuevo run (se mantiene en memoria hasta `end_run()`).

#### `log_metric()`
```python
def log_metric(
    run_id: str,
    key: str,
    value: float,
    step: int = 0,
    metadata: Dict = None,
) -> None
```

Loguea m√©trica para run (ej: loss, accuracy).

#### `log_parameter()`
```python
def log_parameter(
    run_id: str,
    key: str,
    value: Any,
) -> None
```

Loguea hiperpar√°metro.

#### `log_artifact()`
```python
def log_artifact(
    run_id: str,
    artifact_path: str,
    destination: str = "",
) -> str
```

Loguea artefacto (archivo o directorio). Retorna URI en storage.

#### `end_run()`
```python
def end_run(
    run_id: str,
    status: RunStatus = RunStatus.COMPLETED,
) -> Run
```

Termina run y persiste a storage.

#### `get_run()` ‚Üí `Run`

Obtiene run por ID (activo o persistido).

#### `list_runs()` ‚Üí `List[Dict]`
```python
def list_runs(
    experiment_id: str,
    status_filter: RunStatus = None,
    tag_filter: Dict = None,
) -> List[Dict]
```

Lista runs en experimento con filtros opcionales.

#### `compare_runs()` ‚Üí `pd.DataFrame`
```python
def compare_runs(
    run_ids: List[str]
) -> pd.DataFrame
```

Compara m√∫ltiples runs como DataFrame (columnas = m√©tricas/par√°metros).

#### `search_runs()` ‚Üí `List[str]`
```python
def search_runs(
    experiment_id: str,
    metric_filter: Dict = None,  # {"metric": (">", threshold)}
) -> List[str]
```

Busca runs que cumplen condiciones de m√©tricas.

---

## Ejemplos Completos

### Entrenamiento de Modelo

```python
from tauro.core.mlops.config import MLOpsContext
from tauro.core.mlops.experiment_tracking import RunStatus
import pickle

ctx = MLOpsContext(backend_type="local", storage_path="./mlops")
tracker = ctx.experiment_tracker
registry = ctx.model_registry

# Crear experimento
exp = tracker.create_experiment("xgboost_tuning")

# Trial 1
run1 = tracker.start_run(
    exp.experiment_id,
    name="trial_1",
    parameters={"depth": 5, "lr": 0.1, "n_estimators": 100}
)

# Entrenar y loguear
model1 = train_model(depth=5, lr=0.1, n_estimators=100)
for epoch, metrics in training_loop(model1, train_data):
    tracker.log_metric(run1.run_id, "train_loss", metrics["loss"], step=epoch)
    tracker.log_metric(run1.run_id, "train_auc", metrics["auc"], step=epoch)

# Guardar y loguear artefacto
with open("model_trial1.pkl", "wb") as f:
    pickle.dump(model1, f)
tracker.log_artifact(run1.run_id, "model_trial1.pkl")

# Evaluar
eval_metrics = evaluate(model1, test_data)
tracker.log_metric(run1.run_id, "test_auc", eval_metrics["auc"], step=0)
tracker.log_metric(run1.run_id, "test_accuracy", eval_metrics["accuracy"], step=0)

tracker.end_run(run1.run_id, RunStatus.COMPLETED)

# Trial 2 (mejor config)
run2 = tracker.start_run(
    exp.experiment_id,
    name="trial_2",
    parameters={"depth": 8, "lr": 0.05, "n_estimators": 200}
)
# ... similar logging ...

# Comparar y elegir mejor
comparison = tracker.compare_runs([run1.run_id, run2.run_id])
print(comparison)

best_run_id = run2.run_id
best_run = tracker.get_run(best_run_id)

# Registrar en Model Registry
registry.register_model(
    name="xgboost_classifier",
    artifact_path="model_trial2.pkl",
    artifact_type="xgboost",
    framework="xgboost",
    hyperparameters=best_run.parameters,
    metrics={"test_auc": 0.97, "test_accuracy": 0.91},
    experiment_run_id=best_run_id,
)

# Promover a producci√≥n
registry.promote_model("xgboost_classifier", 1, ModelStage.PRODUCTION)
```

---

## üéì Resumen: Tres Formas de Usar MLOps

### 1. ETL Pipeline (Sin MLOps)
```yaml
# config/nodes.yaml
nodes:
  load_data:
    function: "etl.load_csv"
  transform:
    function: "etl.clean_data"
# ‚úÖ MLOps auto-deshabilitado ‚Üí Sin overhead
```

### 2. ML Pipeline Simple (Auto todo)
```yaml
# config/nodes.yaml
nodes:
  train_model:  # ‚Üê AUTO-DETECTADO
    function: "ml.train_xgboost"
# ‚úÖ MLOps auto-habilitado
# ‚úÖ Backend desde global_settings
# ‚úÖ Experiment tracking autom√°tico
```

### 3. ML Production (ml_info.yaml)
```yaml
# config/ml_info.yaml
mlops:
  enabled: true
  backend: "databricks"
  experiment:
    name: "production-model"
  model_registry:
    catalog: "main"
    schema: "ml_models"

# config/nodes.yaml
nodes:
  train_model:
    function: "ml.train_xgboost"
    mlops:
      experiment_name: "xgboost-v2"  # Override selectivo
# ‚úÖ Configuraci√≥n centralizada
# ‚úÖ Override granular
# ‚úÖ Reusabilidad entre pipelines
```

## Integraci√≥n con Spark/Databricks

Para escribir en Unity Catalog desde Spark:

```python
# En Databricks notebook
spark.createDataFrame(
    comparison_df
).write.mode("overwrite").option(
    "overwriteSchema", "true"
).saveAsTable("catalog.schema.run_comparison")
```

---

## Limitaciones Actuales

1. **DatabricksStorageBackend**: Actualmente es una integraci√≥n parcial. Para operaciones de lectura/escritura en UC se recomienda usar Spark API directamente.
2. **M√©tricas**: Se almacenan en memoria durante run y se persisten al terminar.
3. **Runs anidados**: Soportados pero sin validaci√≥n de ciclos.
4. **Concurrencia**: No hay mecanismo de locking para escribura concurrente.

---

## Roadmap

- [ ] Integraci√≥n completa con Databricks UC (volumes)
- [ ] M√©tricas incrementales (sin cargar todo en memoria)
- [ ] Validaci√≥n de esquemas (input/output)
- [ ] Modelo Registry API HTTP
- [ ] UI Web para visualizaci√≥n
- [ ] Integraci√≥n con MLflow

---

## Desarrollo

Ejecutar ejemplos:

```bash
cd tauro/core/mlops
python example.py
```

---

## License

MIT - Ver LICENSE en ra√≠z del proyecto.
