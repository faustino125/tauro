# MLOps Layer

Integrated MLOps layer for Tauro providing **Model Registry** and **Experiment Tracking**, with dual support for local storage (Parquet) and Databricks Unity Catalog.

## ðŸŽ¯ Philosophy: Invisible Until Needed

MLOps in Tauro is designed to be:
- **Zero-config for ETL**: Does not interfere with data-only pipelines
- **Auto-activated for ML**: Automatically detects ML nodes
- **Progressively complex**: Simple configuration by default, fine-grained control when needed

---

## âœ¨ Features

### Model Registry
- âœ… Automatic model versioning
- âœ… Structured metadata (framework, hyperparameters, metrics)
- âœ… Artifact storage (sklearn, XGBoost, PyTorch, etc.)
- âœ… Lifecycle management (Staging â†’ Production â†’ Archived)
- âœ… Search by name, version, and stage
- âœ… Tags and annotations

### Experiment Tracking
- âœ… Experiment and run creation
- âœ… Metric logging (with timestamps and steps)
- âœ… Hyperparameter logging
- âœ… Artifact storage per run
- âœ… Run comparison (DataFrame)
- âœ… Run search by metrics
- âœ… Nested run support (parent-child)

### Backends
- âœ… **Local**: Parquet storage (no external dependencies)
- âœ… **Databricks**: Unity Catalog (with databricks-sql-connector)

### ðŸ†• Event System and Observability
- âœ… **EventEmitter**: Pub/sub event system with history
- âœ… **MetricsCollector**: Metrics collection (counters, gauges, timers)
- âœ… **HooksManager**: Pre/post hooks for operations
- âœ… **AuditLogger**: Audit logging with queries

### ðŸ†• Cache Layer
- âœ… **LRUCache**: Thread-safe LRU cache with TTL
- âœ… **TwoLevelCache**: Two-level cache (L1 memory / L2 storage)
- âœ… **BatchProcessor**: Batch operation processing
- âœ… **CachedStorage**: Cache wrapper for storage backends

### ðŸ†• Health Checks and Diagnostics
- âœ… **HealthMonitor**: Central system health monitor
- âœ… **StorageHealthCheck**: Storage status verification
- âœ… **MemoryHealthCheck**: Memory usage monitoring
- âœ… **DiskHealthCheck**: Disk space verification
- âœ… **Liveness** and **readiness** probes (Kubernetes-style)

### ðŸ†• Improved Architecture
- âœ… **Protocols**: Abstract interfaces for all components
- âœ… **Base Classes**: Base classes with lifecycle management
- âœ… **Enhanced Exceptions**: Exceptions with error codes and context
- âœ… **Resilience**: Retry policies and circuit breakers

---

## ðŸš€ Quick Start

### Installation

```bash
pip install pandas loguru pyarrow

# For Databricks (optional)
pip install databricks-sql-connector
```

### Basic Usage

```python
from engine.mlops import (
    MLOpsContext,
    init_mlops,
    get_mlops_context,
    ModelStage,
    RunStatus,
)

# Initialize MLOps context
ctx = init_mlops(backend_type="local", storage_path="./mlops_data")

# Or using the global context
mlops = get_mlops_context()
```

### Model Registry

```python
registry = ctx.model_registry

# Register model
model_v1 = registry.register_model(
    name="credit_risk_model",
    artifact_path="/path/to/model.pkl",
    artifact_type="sklearn",
    framework="scikit-learn",
    hyperparameters={"n_estimators": 100, "max_depth": 10},
    metrics={"accuracy": 0.92, "auc": 0.95},
    tags={"team": "ds", "project": "credit"}
)

# Promote to production
registry.promote_model("credit_risk_model", 1, ModelStage.PRODUCTION)

# Get production model
prod_model = registry.get_model_by_stage("credit_risk_model", ModelStage.PRODUCTION)
```

### Experiment Tracking

```python
tracker = ctx.experiment_tracker

# Create experiment
exp = tracker.create_experiment(
    name="model_tuning_v1",
    description="Hyperparameter tuning",
    tags={"team": "ds"}
)

# Start run with context manager
with tracker.run_context(exp.experiment_id, name="trial_1") as run:
    for epoch in range(10):
        tracker.log_metric(run.run_id, "loss", 0.5 - epoch * 0.05, step=epoch)
        tracker.log_metric(run.run_id, "accuracy", 0.7 + epoch * 0.03, step=epoch)
    tracker.log_artifact(run.run_id, "/path/to/model.pkl")
# Run is automatically finalized
```

---

## ðŸ†• Event System

```python
from engine.mlops import (
    EventEmitter, 
    EventType, 
    get_event_emitter,
    get_metrics_collector,
)

# Get global event emitter
emitter = get_event_emitter()

# Subscribe to events
def on_model_registered(event):
    print(f"Model registered: {event.data}")

emitter.subscribe(EventType.MODEL_REGISTERED, on_model_registered)

# Events are automatically emitted by components
# You can also emit events manually:
emitter.emit(EventType.MODEL_REGISTERED, {"name": "my_model", "version": 1})
```

### Metrics

```python
metrics = get_metrics_collector()

# Counters
metrics.increment("models_registered")
metrics.increment("api_requests", tags={"endpoint": "/models"})

# Gauges
metrics.gauge("active_runs", 5)

# Timers
with metrics.timer("training_duration"):
    train_model()

# Get summary
summary = metrics.get_summary()
print(summary)
```

### Hooks

```python
from engine.mlops import HooksManager, HookType, get_hooks_manager

hooks = get_hooks_manager()

# Register pre-operation hook
@hooks.register(HookType.PRE_MODEL_REGISTER)
def validate_model(data):
    if data.get("metrics", {}).get("accuracy", 0) < 0.5:
        raise ValueError("Model accuracy too low")
    return data

# Register post-operation hook
@hooks.register(HookType.POST_MODEL_REGISTER)
def notify_slack(data):
    send_slack_notification(f"New model: {data['name']}")
    return data
```

---

## ðŸ†• Cache Layer

```python
from engine.mlops import LRUCache, TwoLevelCache, CachedStorage

# Simple LRU cache
cache = LRUCache(max_size=1000, default_ttl=300)  # 5 min TTL
cache.set("model:v1", model_metadata)
cached = cache.get("model:v1")

# Two-level cache
l1_cache = LRUCache(max_size=100, default_ttl=60)   # Fast, small
l2_cache = LRUCache(max_size=10000, default_ttl=3600)  # Large, slow
two_level = TwoLevelCache(l1=l1_cache, l2=l2_cache)

# Storage wrapper with cache
cached_storage = CachedStorage(storage=storage_backend, cache=cache)
# Reads are automatically cached
data = cached_storage.read_json("path/to/config.json")
```

### Batch Processing

```python
from engine.mlops import BatchProcessor, BatchOperation

def process_batch(operations):
    for op in operations:
        storage.write(op.key, op.value)

processor = BatchProcessor(
    process_func=process_batch,
    batch_size=100,
    flush_interval=5.0  # seconds
)

# Operations accumulate and are processed in batches
processor.add(BatchOperation(key="k1", value="v1", operation_type="write"))
processor.add(BatchOperation(key="k2", value="v2", operation_type="write"))
# Manual flush if needed
processor.flush()
```

---

## ðŸ†• Health Checks

```python
from engine.mlops import (
    HealthMonitor,
    StorageHealthCheck,
    MemoryHealthCheck,
    DiskHealthCheck,
    get_health_monitor,
    check_health,
    is_healthy,
    is_ready,
)

# Get global monitor
monitor = get_health_monitor()

# Register health checks
monitor.register(StorageHealthCheck("storage", storage_backend))
monitor.register(MemoryHealthCheck("memory", warning_threshold=0.8))
monitor.register(DiskHealthCheck("disk", path="/data", warning_threshold=0.9))

# Check health
report = check_health()
print(f"Status: {report.overall_status}")
for check in report.checks:
    print(f"  {check.name}: {check.status} - {check.message}")

# Kubernetes-style probes
if is_healthy():  # Liveness
    print("System is alive")

if is_ready():  # Readiness
    print("System is ready to accept traffic")
```

---

## ðŸ†• Enhanced Exceptions

```python
from engine.mlops import (
    ErrorCode,
    ErrorContext,
    MLOpsException,
    ModelNotFoundError,
    create_error_response,
    wrap_exception,
)

# Exceptions with error codes
try:
    model = registry.get_model_version("nonexistent")
except ModelNotFoundError as e:
    print(f"Error code: {e.error_code}")  # ErrorCode.MODEL_NOT_FOUND
    print(f"Context: {e.context}")

# Create error response for APIs
response = create_error_response(
    error_code=ErrorCode.VALIDATION_ERROR,
    message="Invalid model name",
    details={"field": "name", "reason": "Must be alphanumeric"}
)

# Wrap external exceptions
try:
    external_operation()
except Exception as e:
    raise wrap_exception(e, ErrorCode.STORAGE_ERROR, "Failed to save model")
```

---

## ðŸ†• Protocols (Interfaces)

The system defines clear interfaces for all components:

```python
from engine.mlops import (
    StorageBackendProtocol,
    ExperimentTrackerProtocol,
    ModelRegistryProtocol,
    LockProtocol,
    EventEmitterProtocol,
)

# Create custom implementation
class MyCustomStorage:
    """Implements StorageBackendProtocol."""
    
    def write_dataframe(self, df, path, mode="overwrite"):
        ...
    
    def read_dataframe(self, path):
        ...
    
    # ... remaining methods

# Type checking works automatically
def process_data(storage: StorageBackendProtocol):
    df = storage.read_dataframe("data.parquet")
    ...
```

---

## ðŸ“¦ Architecture

```
engine/mlops/
â”œâ”€â”€ __init__.py              # Public API exports
â”œâ”€â”€ config.py                # MLOpsContext, configuration, and factories
â”œâ”€â”€ storage.py               # Storage backends (Local, Databricks)
â”œâ”€â”€ model_registry.py        # Model Registry implementation
â”œâ”€â”€ experiment_tracking.py   # Experiment Tracking implementation
â”‚
â”œâ”€â”€ protocols.py             # Abstract interfaces (Protocols)
â”œâ”€â”€ events.py                # Event system, metrics, hooks, audit
â”œâ”€â”€ cache.py                 # Caching layer (LRU, TwoLevel, Batch)
â”œâ”€â”€ base.py                  # Base classes and mixins
â”œâ”€â”€ health.py                # Health checks and diagnostics
â”œâ”€â”€ exceptions.py            # Enhanced exceptions with error codes
â”‚
â”œâ”€â”€ concurrency.py           # ðŸ†• Consolidated: locks, transactions
â”œâ”€â”€ mlflow.py                # ðŸ†• Consolidated: MLflow integration
â”œâ”€â”€ resilience.py            # Retry policies, circuit breakers
â”œâ”€â”€ validators.py            # Input validation
â”‚
â””â”€â”€ test/                    # Unit tests
    â”œâ”€â”€ test_protocols.py
    â”œâ”€â”€ test_events.py
    â”œâ”€â”€ test_cache.py
    â”œâ”€â”€ test_base.py
    â”œâ”€â”€ test_health.py
    â”œâ”€â”€ test_locking.py
    â”œâ”€â”€ test_transaction.py
    â””â”€â”€ test_factory.py
```

### Consolidated Modules (v2.0)

| Module | Contains | Replaces |
|--------|----------|----------|
| `concurrency.py` | FileLock, OptimisticLock, ReadWriteLock, Transaction, SafeTransaction | `locking.py`, `transaction.py` |
| `mlflow.py` | MLflowPipelineTracker, mlflow_track decorator, MLflowHelper | `mlflow_adapter.py`, `mlflow_decorators.py`, `mlflow_utils.py` |
| `config.py` | MLOpsContext, factories (StorageBackendFactory, etc.) | Original `config.py` + `factory.py` |

### Main Components

| Component | Description |
|-----------|-------------|
| `StorageBackend` | Abstraction for local (Parquet) and Databricks (Unity Catalog) |
| `ModelRegistry` | Model versioning, lifecycle, artifacts |
| `ExperimentTracker` | Experiments, runs, metrics, parameters |
| `MLOpsContext` | Factory and centralized configuration |
| `EventEmitter` | Pub/sub system for events |
| `MetricsCollector` | Operational metrics collection |
| `HooksManager` | Pre/post hooks for extensibility |
| `LRUCache` | In-memory cache with TTL |
| `HealthMonitor` | Health checks and diagnostics |

---

## ðŸ”§ Configuration

### Environment Variables

```bash
# Local backend
TAURO_MLOPS_BACKEND=local
TAURO_MLOPS_PATH=/path/to/mlops/data

# Databricks backend
TAURO_MLOPS_BACKEND=databricks
TAURO_MLOPS_CATALOG=my_catalog
TAURO_MLOPS_SCHEMA=mlops
DATABRICKS_HOST=https://workspace.cloud.databricks.com
DATABRICKS_TOKEN=dapi1234567890abcdef
```

### Configuration with ml_info.yaml

```yaml
# config/ml_info.yaml
mlops:
  enabled: true
  backend: "databricks"
  experiment:
    name: "customer-churn-prediction"
    description: "Customer churn prediction model"
  model_registry:
    catalog: "main"
    schema: "ml_models"
  tracking:
    catalog: "main"
    schema: "ml_experiments"
  auto_log: true
  
  # ðŸ†• Cache configuration
  cache:
    enabled: true
    max_size: 1000
    default_ttl: 300
  
  # ðŸ†• Health checks configuration
  health:
    enabled: true
    memory_threshold: 0.85
    disk_threshold: 0.90
```

---

## ðŸ“Š Data Structure

### Model Registry

```
model_registry/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ index.parquet              # Model index
â”œâ”€â”€ metadata/
â”‚   â””â”€â”€ {model_id}/
â”‚       â”œâ”€â”€ v1.json                # Metadata v1
â”‚       â””â”€â”€ v2.json                # Metadata v2
â””â”€â”€ artifacts/
    â””â”€â”€ {model_id}/
        â”œâ”€â”€ v1/                    # Artifacts v1
        â””â”€â”€ v2/                    # Artifacts v2
```

### Experiment Tracking

```
experiment_tracking/
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ index.parquet              # Experiment index
â”‚   â””â”€â”€ {exp_id}.json              # Experiment metadata
â”œâ”€â”€ runs/
â”‚   â””â”€â”€ {exp_id}/
â”‚       â”œâ”€â”€ index.parquet          # Run index
â”‚       â””â”€â”€ {run_id}.json          # Run metadata
â””â”€â”€ artifacts/
    â””â”€â”€ {run_id}/                  # Run artifacts
```

---

## ðŸ§ª Testing

```bash
# Run all mlops module tests
pytest engine/mlops/test/ -v

# Specific tests
pytest engine/mlops/test/test_protocols.py -v
pytest engine/mlops/test/test_events.py -v
pytest engine/mlops/test/test_cache.py -v
pytest engine/mlops/test/test_health.py -v
```

---

## ðŸ“š API Reference

### Main Exports

```python
from engine.mlops import (
    # Context and Config
    MLOpsContext, MLOpsConfig, init_mlops, get_mlops_context,
    
    # Protocols
    StorageBackendProtocol, ExperimentTrackerProtocol, ModelRegistryProtocol,
    
    # Events
    EventType, Event, EventEmitter, MetricsCollector, HooksManager, AuditLogger,
    get_event_emitter, get_metrics_collector, get_hooks_manager,
    
    # Cache
    LRUCache, TwoLevelCache, BatchProcessor, CachedStorage, CacheKeyBuilder,
    
    # Health
    HealthMonitor, HealthStatus, StorageHealthCheck, MemoryHealthCheck,
    get_health_monitor, check_health, is_healthy, is_ready,
    
    # Base
    BaseMLOpsComponent, ComponentState, ValidationMixin, PathManager,
    
    # Model Registry
    ModelRegistry, ModelMetadata, ModelVersion, ModelStage,
    
    # Experiment Tracking
    ExperimentTracker, Experiment, Run, Metric, RunStatus,
    
    # Storage
    LocalStorageBackend, DatabricksStorageBackend,
    
    # Exceptions
    ErrorCode, MLOpsException, ModelNotFoundError, ExperimentNotFoundError,
    
    # Resilience
    RetryConfig, with_retry, CircuitBreaker,
)
```

---

## ðŸŽ“ Usage Examples

### 1. ETL Pipeline (No MLOps)

```yaml
nodes:
  load_data:
    function: "etl.load_csv"
  transform:
    function: "etl.clean_data"
# âœ… MLOps auto-disabled â†’ No overhead
```

### 2. ML Pipeline with Full Tracking

```python
from engine.mlops import (
    init_mlops, ModelStage, RunStatus,
    get_event_emitter, get_metrics_collector,
)

# Initialize
ctx = init_mlops(backend_type="local", storage_path="./mlops")
tracker = ctx.experiment_tracker
registry = ctx.model_registry

# Operational metrics
metrics = get_metrics_collector()

# Create experiment
exp = tracker.create_experiment("xgboost_tuning")
metrics.increment("experiments_created")

# Train with tracking
with tracker.run_context(exp.experiment_id, name="trial_1") as run:
    with metrics.timer("training_time"):
        model = train_model(params)
    
    # Log metrics
    tracker.log_metric(run.run_id, "accuracy", 0.95)
    tracker.log_metric(run.run_id, "auc", 0.98)
    
    # Log artifact
    tracker.log_artifact(run.run_id, "model.pkl")
    metrics.increment("models_trained")

# Register best model
version = registry.register_model(
    name="xgboost_classifier",
    artifact_path="model.pkl",
    artifact_type="xgboost",
    framework="xgboost",
    metrics={"accuracy": 0.95, "auc": 0.98},
)
metrics.increment("models_registered")

# Promote to production
registry.promote_model("xgboost_classifier", version.version, ModelStage.PRODUCTION)
```

### 3. Health Monitoring in Production

```python
from engine.mlops import (
    get_health_monitor, StorageHealthCheck, MemoryHealthCheck,
    DiskHealthCheck, ComponentHealthCheck,
)

# Configure health checks
monitor = get_health_monitor()
monitor.register(StorageHealthCheck("storage", ctx.storage))
monitor.register(MemoryHealthCheck("memory", warning_threshold=0.8))
monitor.register(DiskHealthCheck("disk", path="./mlops", warning_threshold=0.9))
monitor.register(ComponentHealthCheck("registry", ctx.model_registry))

# Health check endpoint (Flask example)
@app.route("/health")
def health():
    report = monitor.check_all()
    status_code = 200 if report.is_healthy else 503
    return jsonify(report.to_dict()), status_code

@app.route("/ready")
def ready():
    return ("OK", 200) if monitor.is_ready() else ("Not Ready", 503)
```

---

## ðŸ›£ï¸ Roadmap

- [x] Event system and observability
- [x] Cache layer with LRU and TTL
- [x] Health checks and diagnostics
- [x] Enhanced exceptions with error codes
- [x] Protocols (abstract interfaces)
- [ ] Full Databricks UC integration (volumes)
- [ ] Incremental metrics (streaming)
- [ ] Web UI for visualization
- [ ] MLflow integration
- [ ] Distributed model support

---

## ðŸ“„ License

MIT - See LICENSE in project root.
